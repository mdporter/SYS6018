---
title: "Homework #9: Feature Importance" 
author: "**Your Name Here**"
date: "Due: Fri Apr 21 | 11:45pm"
output: R6018::homework
---

**SYS 4582/6018 | Spring 2023 | University of Virginia **

*******************************************
```{r config, echo=FALSE}
source(system.file("config/hw_config.R", package="R6018")) # knitr settings
# options(dplyr.summarise.inform = FALSE)  # ignore dplyr message about grouping
```

::: {style="background-color:yellow; color:red; display: block; border-color: black; padding:1em"}
This is an **independent assignment**. Do not discuss or work with classmates.
:::

# Required R packages and Directories

::: {.solution}
```{r packages, message=FALSE, warning=FALSE}
data.dir = 'https://mdporter.github.io/SYS6018/data/' # data directory
library(R6018)     # functions for SYS-6018
library(tidyverse) # functions for data manipulation   
```
:::



# Problem 1: Permutation Feature Importance 

The [R package `titanic`](https://cran.r-project.org/web/packages/titanic/index.html) contains data on who survived the Titanic sinking. The passengers have been split into a training (`titanic_train`) and testing (`titanic_test`) set. We are going to use this data to investigate feature importance.
Use `Pclass`, `Sex`, `Age`, `Fare`, `SibSp`, `Parch`, and `Embarked` for the predictor variables (features) and `Survived` as the outcome variable. 

::: {style="background-color:lightblue; display: block;"}

NOTE: Use the training data `titanic_train` as the test data. We would not usually do this, but after posting the homework I was notified that the test data does not contain the labels which prohibits analysis of the permutation feature importance scores. 
In summary, set `test = titanic_*train*`.  

:::

## a. Method 1: Built-in importance scores

Fit a tree ensemble model (e.g., Random Forest, boosted tree) on the training data. You are free to use any method to select the tuning parameters.

Report the built-in feature importance scores and produce a barplot with feature on the x-axis and importance on the y-axis. 

::: {.solution}
Add solution here
:::

## b. Performance 

Report the performance of the model from (a.) on the test data. Use the log-loss (where $M$ is the size of the test data):
$$ 
\text{log-loss}(\hat{p}) = - \frac{1}{M} \sum_{i=1}^m [y_i \log \, \hat{p}_i + (1 - y_i) \log \, (1 - \hat{p}_i)]
$$

::: {.solution}
Add solution here
:::

## c. Method 2: Permute *after* fitting

Use the fitted model from question (a.) to perform permutation feature importance. Shuffle/permute each variable individually on the *test set* before making predictions. Record the loss. Repeat $M=10$ times and produce a boxplot of the change in loss (change from reported loss from part b.). 

::: {.solution}
Add solution here
:::

## d. Method 3: Permute *before* fitting

For this approach, shuffle/permute the *training data* and re-fit the ensemble model. Evaluate the predictions on the (unaltered) test data. Repeat $M=10$ times (for each predictor variable) and produce a boxplot of the change in loss. 

::: {.solution}
Add solution here
:::


## e. Understanding 

Describe the benefits of each of the three approaches to measure feature importance. 

::: {.solution}
Add solution here
:::

# Problem 2: Effects of correlated predictors

This problem will illustrate what happens to the importance scores when there are highly associated predictors. 

## a. Create an almost duplicate feature

Create a new feature `Sex2` that is 95% the same as `Sex`. Do this by selecting 5% of training ($n=45$) and testing ($n=21$) data and flip the `Sex` value. 

::: {.solution}
Add solution here
:::

## b. Method 1: Built-in importance

Fit the same model as in Problem 1a, but use the new data that includes `Sex2` (i.e., use both `Sex` and `Sex2` in the model). Calculate the built-in feature importance score and produce a boxplot. 

::: {.solution}
Add solution here
:::



## c. Method 2: Permute *after* fitting

Redo Method 2 (problem 1c) on the new data/model and produce a boxplot of importance scores. 

::: {.solution}
Add solution here
:::

## d. Method 3: Permute *before* fitting

Redo Method 3 (problem 1d) on the new data and produce a boxplot of importance scores. 

::: {.solution}
Add solution here
:::


## e. Understanding

Describe how the addition of the almost duplicated predictor impacted the feature importance results.  

::: {.solution}
Add solution here
:::


